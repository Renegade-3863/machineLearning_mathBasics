## Covariance Matrix（协方差矩阵）
#### 什么是协方差矩阵？

方差的概念大家都不陌生，可以解释为用于衡量一组数据相对其均值的散布程度的度量值

那么什么是 “协” 方差？
- 我们定义一组数据 $\{{x}\}_1^n$ 的方差 $\sigma^2(x)$ 为 $$\sigma^2(x) = \frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})^2$$
- 而一组数据 $\{{x}\}_1^n$ 的 ”协方差” $Cov(x,y)$ 我们定义为：$$Cov(x,y) = \frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}) $$

不难看出，方差实际上就是样本维度 x 和自己的协方差，即：$\sigma^2(x)$ = $Cov(x,x)$
- 不过也有另一种定义协方差的方式，前面的分式是 $\frac{1}{n-1}$，不过为了方便理解，我们这里先用 $\frac{1}{n}$

#### 如何理解协方差？
上面给出的是协方差的计算公式，我们还需要明白这个公式在度量什么。

先给结论：协方差 $Cov(x, y)$，代表的是维度 x 和维度 y 之间的正相关/负相关/无相关性

观察这个计算公式：$$Cov(x,y) = \frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}) $$
- 不难发现，对于每一个样本（其中包含 $(x_i, y_i)$ 两个维度值，如果同时出现 $x_i \gt \bar{x} $ 和 $y_i \gt \bar{y}$，那么这一项的乘积就是正的，
- 依上面的方式来理解，我们就可以明白，这个求和和平均，实际上是在求解两个维度之间的 “相对值” 变化的趋势

|x|y|Cov(x,y)|
|---|---|---|
|> $\bar{x}$ |> $\bar{y}$| > 0|
|> $\bar{x}$ |< $\bar{y}$| < 0|
|< $\bar{x}$ |> $\bar{y}$| < 0|
|< $\bar{x}$ |< $\bar{y}$| > 0|

观察上面的表格，不难发现，如果某个数据点上，$x_i$ 和 $y_i$ 在各自维度均值的同侧，那么总体的协方差累计值会是负数（代表 $x_i$ 和 $y_i$ 起码在这个维度上是正相关的，反之同理。

最后累加了所有样本中 x 维和 y 维之间的关系后，我们就拿到了总体的 “协方差”

如果这个值是个正数，我们就说：**“数据集的 x 维和 y 维之间有正相关的倾向”**，而如果这个值是个负数，我们就说：“数据集的 x 维和 y 维之间有负相关的倾向“，而这些值的绝对值越大，就代表了对应相关性的程度。特别的，如果这个值为 0，那么我们就说二者没有相关性。

### Takeaway
- 协方差矩阵在 Machine Learning 的很多领域都有很深刻的应用，例如针对数据集中各维度间相关性的消除问题

- TODO：完善协方差矩阵的功能列表
